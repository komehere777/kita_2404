{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0823"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.gradio.app/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "MODEL = \"gpt-4o-mini-2024-07-18\"\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradioëŠ” Python ê¸°ë°˜ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë˜ëŠ” ì¼ë°˜ì ì¸ í•¨ìˆ˜ì™€ ì‚¬ìš©ì ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ ê°„ë‹¨í•˜ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤. Gradioë¥¼ ì‚¬ìš©í•˜ë©´ ëª‡ ì¤„ì˜ ì½”ë“œë¡œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ë‚˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš©ìì—ê²Œ ì‰½ê²Œ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒì—…ì  ë°°í¬ëŠ” ì–´ë µì§€ë§Œ ë°°í¬ê°€ëŠ¥, ë°ëª¨ë‚˜ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ì¢‹ë‹¤.\n",
    "\n",
    "**Gradioì˜ ê¸°ë³¸ ê°œë…**\n",
    "\n",
    "- ì›¹ ì¸í„°í˜ì´ìŠ¤: GradioëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë˜ëŠ” ì¼ë°˜ì ì¸ íŒŒì´ì¬ í•¨ìˆ˜ë¥¼ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ UIë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì‚¬ìš©ìëŠ” ëª¨ë¸ì„ ì§ì ‘ ì…ë ¥ê°’ì„ ì£¼ê±°ë‚˜ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- ì‚¬ìš©ì ìƒí˜¸ì‘ìš©: GradioëŠ” í…ìŠ¤íŠ¸ ì…ë ¥, íŒŒì¼ ì—…ë¡œë“œ, ë“œë¡­ë‹¤ìš´ ë©”ë‰´ ë“± ë‹¤ì–‘í•œ ìœ„ì ¯ì„ ì œê³µí•˜ì—¬ ì‚¬ìš©ìê°€ ì‰½ê²Œ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤. ì‰½ê³  ì§ê´€ì ì¸ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤. ëª¨ë“ˆí™”í•´ ë†“ìŒ, \n",
    "- ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘: ë³µì¡í•œ ì›¹ ì„œë²„ ì„¤ì • ì—†ì´ë„ ê°„ë‹¨í•˜ê²Œ ëª¨ë¸ì„ ì›¹ì—ì„œ í…ŒìŠ¤íŠ¸í•˜ê³  ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**Gradioì˜ í•µì‹¬ ê¸°ëŠ¥**\n",
    "- ì¸í„°í˜ì´ìŠ¤ êµ¬ì„± ìš”ì†Œ:\n",
    "GradioëŠ” ë‹¤ì–‘í•œ ì…ë ¥ ë° ì¶œë ¥ ìœ„ì ¯ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ ê¸°ë°˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "  - ì…ë ¥ ìœ„ì ¯: Textbox, Dropdown, Slider, Checkbox, FileUpload ë“±\n",
    "  - ì¶œë ¥ ìœ„ì ¯: Textbox, Label, Image, Audio, Video ë“±\n",
    "\n",
    "-  Interface: Gradioì˜ ê¸°ë³¸ í´ë˜ìŠ¤ì…ë‹ˆë‹¤. í•¨ìˆ˜ë¥¼ UI ìœ„ì ¯ê³¼ ì—°ê²°í•˜ì—¬ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "  - fn: ì‹¤í–‰í•  í•¨ìˆ˜\n",
    "  - inputs: ì‚¬ìš©ì ì…ë ¥ì„ ë°›ëŠ” ìœ„ì ¯\n",
    "  - outputs: í•¨ìˆ˜ì˜ ê²°ê³¼ë¥¼ í‘œì‹œí•˜ëŠ” ìœ„ì ¯\n",
    "  \n",
    "- Blocks: ë³µì¡í•œ ë ˆì´ì•„ì›ƒì„ ë§Œë“¤ê±°ë‚˜ ì—¬ëŸ¬ ìœ„ì ¯ì„ ì—°ê²°í•  ë•Œ ì‚¬ìš©ë˜ëŠ” ë¸”ë¡ êµ¬ì¡°ì…ë‹ˆë‹¤. BlocksëŠ” ì—¬ëŸ¬ ì»´í¬ë„ŒíŠ¸ë¥¼ `ëª¨ë“ˆì‹`ìœ¼ë¡œ êµ¬ì„±í•  ìˆ˜ ìˆìœ¼ë©°, ë³µì¡í•œ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬ì„±í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ìƒíƒœ ê´€ë¦¬ (gr.State): ì—¬ëŸ¬ í•¨ìˆ˜ í˜¸ì¶œ ê°„ì— ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ê³µìœ í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤. ëŒ€í™”í˜• ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ìƒíƒœë¥¼ ìœ ì§€í•˜ê±°ë‚˜ ì´ì „ ì…ë ¥ê°’ì„ ì €ì¥í•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "- ì‹¤ì‹œê°„ ì¸í„°í˜ì´ìŠ¤: GradioëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³ , ë¹ ë¥´ê²Œ ê²°ê³¼ë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë°ì´í„° ë¶„ì„, ì´ë¯¸ì§€ ìƒì„±, ì±—ë´‡ ë“± ë‹¤ì–‘í•œ ì‹¤ì‹œê°„ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- íŒŒì¼ ì—…ë¡œë“œ ë° ë‹¤ìš´ë¡œë“œ: GradioëŠ” íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ë‹¤ìš´ë¡œë“œí•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ ì‚¬ìš©ìì™€ì˜ ìƒí˜¸ì‘ìš©ì„ ë”ìš± ë‹¤ì–‘í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- Markdown ì§€ì›: GradioëŠ” gr.Markdown()ì„ í†µí•´ ì¸í„°í˜ì´ìŠ¤ì—ì„œ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì„¤ëª…ì„ Markdown í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def greet(name, intensity):\n",
    "    return \"Hello, \" + name + \"!\" * int(intensity)\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", \"slider\"],\n",
    "    outputs=[\"text\"],\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7876\n",
      "Running on public URL: https://390aa1c7893ac0c4c5.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://390aa1c7893ac0c4c5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello, \" + name + \"!\"\n",
    "\n",
    "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello, \" + name + \"!\"\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet, \n",
    "    inputs=gr.Textbox(lines=2, label=\"Name Here...\"),\n",
    "    outputs=\"text\")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name, is_morning, temperature):\n",
    "    salutation = \"Good morning\" if is_morning else \"Hello\"\n",
    "    greeting = f\"{salutation}, {name}, It is {temperature} degrees today!\"\n",
    "    celsius = (temperature - 32) * 5.0/9.0\n",
    "    return greeting, f\"{temperature}Â°F is {celsius}Â°C\"\n",
    "\n",
    "demo = gr.Interface(fn=greet, inputs=[\"text\", \"checkbox\", gr.Slider(0,100)], outputs=[\"text\", \"text\"])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 406, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 70, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\applications.py\", line 123, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\gradio\\route_utils.py\", line 760, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 65, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\routing.py\", line 754, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\routing.py\", line 774, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\routing.py\", line 295, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\routing.py\", line 77, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\routing.py\", line 75, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\responses.py\", line 348, in __call__\n",
      "    await send(\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\_exception_handler.py\", line 50, in sender\n",
      "    await send(message)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\_exception_handler.py\", line 50, in sender\n",
      "    await send(message)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 161, in _send\n",
      "    await send(message)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 510, in send\n",
      "    output = self.conn.send(event=h11.EndOfMessage())\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\h11\\_connection.py\", line 512, in send\n",
      "    data_list = self.send_with_data_passthrough(event)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\h11\\_connection.py\", line 545, in send_with_data_passthrough\n",
      "    writer(event, data_list.append)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\h11\\_writers.py\", line 67, in __call__\n",
      "    self.send_eom(event.headers, write)\n",
      "  File \"d:\\pythonProject\\ML\\venv\\lib\\site-packages\\h11\\_writers.py\", line 96, in send_eom\n",
      "    raise LocalProtocolError(\"Too little data for declared Content-Length\")\n",
      "h11._util.LocalProtocolError: Too little data for declared Content-Length\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "def sepia(input_img):\n",
    "    input_img = resize(input_img, (224, 224))\n",
    "    sepia_filter = np.array(\n",
    "        [\n",
    "            [0.393, 0.769, 0.189],\n",
    "            [0.349, 0.686, 0.168],\n",
    "            [0.272, 0.534, 0.131],\n",
    "        ]\n",
    "    )\n",
    "    sepia_img = input_img.dot(sepia_filter.T)\n",
    "    sepia_img /= sepia_img.max()                          \n",
    "    return sepia_img\n",
    "\n",
    "demo = gr.Interface(sepia, inputs=gr.Image(), outputs=gr.Image())\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7874\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def bmi(name, height, weight, feeling):\n",
    "    bmi_val = round(weight / (height / 100) ** 2, 2)\n",
    "    result_emotion = \"ğŸ˜Š\" if bmi_val < 30 else \"ğŸ˜”\"\n",
    "    output_str = 'Hello {}, your BMI is {} and you are feeling {}'.format(name, bmi_val, feeling)\n",
    "    txt = \"Happy\" if feeling else \"Sad\"\n",
    "    return output_str, result_emotion, txt\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=bmi, \n",
    "    inputs=[\"text\", gr.Slider(30, 200, label=\"Height in cm\"), gr.Slider(0, 100, label=\"Weight in kg\"),\"checkbox\",], \n",
    "    outputs=[\"text\",\"text\", \"text\"],\n",
    "    examples=[[\"John\", 180, 80, True],\n",
    "              [\"Jane\", 160, 70, False],\n",
    "              [\"Jack\", 170, 90, True]],\n",
    "    live=True,\n",
    "    description=\"Flag if you find an erroneous result\"\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocks\n",
    "- Gradioì˜ ì €ìˆ˜ì¤€ APIë¡œ ì¸í„°í˜ì´ìŠ¤ë³´ë‹¤ ë” ë§ì€ ì‚¬ìš©ì ì§€ì • ì›¹ ì‘ìš© í”„ë¡œê·¸ë¨ ë° ë°ëª¨ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤(ì•„ì§ ì™„ì „íˆ Pythonìœ¼ë¡œ).\n",
    "- ì¸í„°í˜ì´ìŠ¤ í´ë˜ìŠ¤ì— ë¹„í•´ BlocksëŠ” ë‹¤ìŒì— ëŒ€í•´ ë” ë§ì€ ìœ ì—°ì„±ê³¼ ì œì–´ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "- BlocksëŠ” ë˜í•œ íƒ­ê³¼ ê°™ì€ ê´€ë ¨ ë°ëª¨ë¥¼ í•¨ê»˜ ê·¸ë£¹í™”í•˜ëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "- Blocks ê°ì²´ë¥¼ ìƒì„±í•œ ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•˜ê³ (\"with\" ë¬¸ ì‚¬ìš©) Blocks ì»¨í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ë ˆì´ì•„ì›ƒ, êµ¬ì„± ìš”ì†Œ ë˜ëŠ” ì´ë²¤íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ launch() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ ë°ëª¨ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7877\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7877/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def greet(name, intensity):\n",
    "    return \"Hello, \" + name + \"!\" * int(intensity)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    text_input = gr.Textbox(lines=2, label=\"Name Here...\")\n",
    "    output = gr.Textbox(lines=2, label=\"Output Here...\")\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    \n",
    "    btn.click(fn=greet, inputs=text_input, outputs=output)\n",
    "\n",
    "demo.launch()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì‹¤ìŠµ \n",
    "ì½”ë”©íŠœí„°ëŠ” ê³ ë“±í•™ìƒ ì •ë³´ê³¼ëª©ì—ì„œ ì•Œê³ ë¦¬ì¦˜ê³¼ í”„ë¡œê·¸ë˜ë°ì„ í•™ìƒë“¤ì´ ì‹¤ìŠµí•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” íŠœí„°ë´‡\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê¸°ë³¸ ëª¨ë¸ - í“¨ìƒ·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì¢‹ì•„ìš”! ë³€ìˆ˜ì™€ ìë£Œí˜•ì— ëŒ€í•´ ì•Œì•„ë³¼ê²Œìš”.\\n\\n**ë³€ìˆ˜**ëŠ” ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ê³µê°„ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, `x = 5`ì—ì„œ `x`ëŠ” ë³€ìˆ˜ì´ê³ , 5ë¼ëŠ” ê°’ì„ ì €ì¥í•©ë‹ˆë‹¤.\\n\\n**ìë£Œí˜•**ì€ ë³€ìˆ˜ì— ì €ì¥ëœ ë°ì´í„°ì˜ ì¢…ë¥˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì£¼ìš” ìë£Œí˜•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\\n1. ì •ìˆ˜(int): 1, 2, 3\\n2. ì‹¤ìˆ˜(float): 1.5, 3.14\\n3. ë¬¸ìì—´(str): \"ì•ˆë…•í•˜ì„¸ìš”\"\\n4. ë¶ˆë¦°(bool): True, False\\n\\nì´í•´í–ˆë‚˜ìš”? ì—°ìŠµë¬¸ì œë¡œ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”! `name`ì´ë¼ëŠ” ë³€ìˆ˜ì— \"í™ê¸¸ë™\"ì„ ì €ì¥í•´ë³´ì„¸ìš”.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "system_msg = \"\"\"ì½”ë”©íŠœí„°ëŠ” ê³ ë“±í•™ìƒ ì •ë³´ê³¼ëª©ì—ì„œ ì•Œê³ ë¦¬ì¦˜ê³¼ í”„ë¡œê·¸ë˜ë°ì„ í•™ìƒë“¤ì´ ì‹¤ìŠµí•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” íŠœí„°ë´‡ì…ë‹ˆë‹¤.\n",
    "              - íŠœí„°ëŠ” \"ë°˜ê°€ì™€ìš”~ \"ë¼ê³  ì¸ì‚¬ë§ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
    "              - í•™ìƒì´ ì„ íƒí•œ ì„¹ì…˜ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•˜ê³  ë¨¼ì € ê°„ë‹¨í•˜ê²Œ ì„¹ì…˜ í•™ìŠµë‚´ìš© ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "              - ê° ì„¹ì…˜ë³„ í•™ìŠµ í•­ëª©ì— ëŒ€í•´ì„œ í•˜ë‚˜ì”© ê°œë…ì„ ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ê³  ì—°ìŠµë¬¸ì œë¥¼ ì¶”ê°€ë¡œ ì œê³µí•´ì„œ ê° ê°œë…ì„ ì´í•´í•˜ì—¬ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì—°ìŠµ ê¸°íšŒë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "              - í•™ìƒì˜ ë‹µë³€ì— ëŒ€í•´ì„œ \"ì˜í–ˆì–´ìš”!\",\"ì¡°ê¸ˆ ë” ìƒê°í•´ë´ìš”~\" ì™€ ê°™ì€ ê¸ì •ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "              - ëŒ€í™”ëŠ” ê°„ê²°í•˜ê²Œ ìœ ì§€í•˜ë©°, ìµœëŒ€ 100ì ì´ë‚´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.ë‹¨ ì½”ë“œëŠ” 300ì ì´ë‚´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "              - íŠœí„°ëŠ” í•™ìƒë“¤ì´ ìê¸°ì£¼ë„ í•™ìŠµì„ í•  ìˆ˜ ìˆë„ë¡ ê°œì¸í™” ëœ í•™ìŠµì„ ì œê³µí•˜ê³  ëª¨ë“  ì§ˆì˜ ì‘ë‹µì„ í•œêµ­ì–´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_msg},\n",
    "        {\"role\": \"user\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”. íŒŒì´ì¬ ê¸°ì´ˆì—¥ ëŒ€í•˜ì—¬ í•™ìŠµì„ ì§€ë„í•´ì¤˜ìš”\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"ë°˜ê°€ì™€ìš”~ íŒŒì´ì¬ ê¸°ì´ˆì— ëŒ€í•´ì„œ í•™ìŠµì„ ì‹œì‘í•´ë³¼ê¹Œìš”? ë¨¼ì € íŒŒì´ì¬ì˜ ê¸°ë³¸ ë¬¸ë²•ê³¼ ê°œë…ã„·ë“¤ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ë³´ê² ìŠµë‹ˆë‹¤.\"},\n",
    "        {\"role\": \"user\", \"content\": \"ë³€ìˆ˜ì™€ ìë£Œí˜•ì— ëŒ€í•´ í•™ìŠµí•˜ê³  ì‹¶ì–´ìš”\"},\n",
    "    ],\n",
    "    temperature=0.5,\n",
    "    max_tokens=300,\n",
    "    top_p=1.0,\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- chat_with_tutor í•¨ìˆ˜: ì´ í•¨ìˆ˜ëŠ” OpenAI APIë¥¼ í˜¸ì¶œí•˜ì—¬ í•™ìƒì˜ ì…ë ¥ì— ëŒ€í•œ íŠœí„°ì˜ ì‘ë‹µì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í•˜ê³  ì´ì–´ì„œ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "- start_chat í•¨ìˆ˜: 'í•™ìŠµ ì‹œì‘' ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ íŠœí„°ì˜ ì¸ì‚¬ë§ê³¼ í•¨ê»˜ ëŒ€í™”ê°€ ì‹œì‘ë©ë‹ˆë‹¤.\n",
    "- Gradio UI:\n",
    "  - start_button: í•™ìŠµì„ ì‹œì‘í•˜ëŠ” ë²„íŠ¼ì…ë‹ˆë‹¤. ëˆ„ë¥´ë©´ íŠœí„°ì˜ ì¸ì‚¬ë§ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.\n",
    "  - tutor_response: íŠœí„°ì˜ ëŒ€ë‹µì„ í‘œì‹œí•˜ëŠ” í…ìŠ¤íŠ¸ë°•ìŠ¤ì…ë‹ˆë‹¤.\n",
    "  - user_input: í•™ìƒì´ ì§ˆë¬¸ì„ ì…ë ¥í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ë°•ìŠ¤ì…ë‹ˆë‹¤.\n",
    "  - submit_button: í•™ìƒì´ ì§ˆë¬¸ì„ ì œì¶œí•˜ëŠ” ë²„íŠ¼ì…ë‹ˆë‹¤.\n",
    "  - gr.State(): ëŒ€í™” ê¸°ë¡ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7879\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7879/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7864 <> https://853c9ac39e402356da.gradio.live\n",
      "Killing tunnel 127.0.0.1:7876 <> https://390aa1c7893ac0c4c5.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "system_msg = \"\"\"ì½”ë”©íŠœí„°ëŠ” ê³ ë“±í•™ìƒ ì •ë³´ê³¼ëª©ì—ì„œ ì•Œê³ ë¦¬ì¦˜ê³¼ í”„ë¡œê·¸ë˜ë°ì„ í•™ìƒë“¤ì´ ì‹¤ìŠµí•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” íŠœí„°ë´‡ì…ë‹ˆë‹¤.\n",
    "              - íŠœí„°ëŠ” \"ë°˜ê°€ì™€ìš”~ \"ë¼ê³  ì¸ì‚¬ë§ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
    "              - í•™ìƒì´ ì„ íƒí•œ ì„¹ì…˜ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•˜ê³  ë¨¼ì € ê°„ë‹¨í•˜ê²Œ ì„¹ì…˜ í•™ìŠµë‚´ìš© ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "              - ê° ì„¹ì…˜ë³„ í•™ìŠµ í•­ëª©ì— ëŒ€í•´ì„œ í•˜ë‚˜ì”© ê°œë…ì„ ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•˜ê³  ì—°ìŠµë¬¸ì œë¥¼ ì¶”ê°€ë¡œ ì œê³µí•´ì„œ ê° ê°œë…ì„ ì´í•´í•˜ì—¬ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì—°ìŠµ ê¸°íšŒë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "              - í•™ìƒì˜ ë‹µë³€ì— ëŒ€í•´ì„œ \"ì˜í–ˆì–´ìš”!\",\"ì¡°ê¸ˆ ë” ìƒê°í•´ë´ìš”~\" ì™€ ê°™ì€ ê¸ì •ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "              - ëŒ€í™”ëŠ” ê°„ê²°í•˜ê²Œ ìœ ì§€í•˜ë©°, ìµœëŒ€ 100ì ì´ë‚´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.ë‹¨ ì½”ë“œëŠ” 300ì ì´ë‚´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "              - íŠœí„°ëŠ” í•™ìƒë“¤ì´ ìê¸°ì£¼ë„ í•™ìŠµì„ í•  ìˆ˜ ìˆë„ë¡ ê°œì¸í™” ëœ í•™ìŠµì„ ì œê³µí•˜ê³  ëª¨ë“  ì§ˆì˜ ì‘ë‹µì„ í•œêµ­ì–´ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "def chat_with_tutor(user_input, chat_history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_msg}] + chat_history\n",
    "    \n",
    "    if not chat_history:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”. íŒŒì´ì¬ ê¸°ì´ˆì—¥ ëŒ€í•˜ì—¬ í•™ìŠµì„ ì§€ë„í•´ì¤˜ìš”\"})\n",
    "        \n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    response_ = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=messages,\n",
    "        temperature=0.5,\n",
    "        max_tokens=300,\n",
    "        top_p=1.0,\n",
    "    )\n",
    "    response_msg = response_.choices[0].message.content\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": response_msg})\n",
    "    \n",
    "    return response_msg, chat_history\n",
    "\n",
    "def start_chat():\n",
    "    return \"ë°˜ê°€ì™€ìš”~ íŒŒì´ì¬ ê¸°ì´ˆì— ëŒ€í•´ì„œ í•™ìŠµì„ ì‹œì‘í•´ë³¼ê¹Œìš”? ë¨¼ì € íŒŒì´ì¬ì˜ ê¸°ë³¸ ë¬¸ë²•ê³¼ ê°œë…ë“¤ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ë“œë¦´ê»˜ìš”\", []\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# íŒŒì´ì¬ íŠœí„° ë´‡\")\n",
    "    \n",
    "    chat_history = gr.State([])\n",
    "    \n",
    "    with gr.Row():\n",
    "        start_btn = gr.Button(\"Start Chat\")\n",
    "    \n",
    "    tutor_response = gr.Textbox(lines=5, label=\"Tutor\")\n",
    "    user_input = gr.Textbox(lines=5, label=\"User\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"Submit\")\n",
    "        \n",
    "    start_btn.click(start_chat, outputs=[tutor_response, chat_history])\n",
    "    submit_btn.click(chat_with_tutor, inputs=[user_input, chat_history], outputs=[tutor_response, chat_history])\n",
    "    \n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë™ê¸°ë¶€ì—¬í•  ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€\n",
    "\n",
    "íˆìŠ¤í† ë¦¬ ì¶œë ¥í•´ì£¼ëŠ” ê¸°ëŠ¥ ì¶”ê°€\n",
    "\n",
    "íƒ­ì„ ì´ìš©í•˜ì—¬ íˆìŠ¤í† ë¦¬ê°€ ë‚˜ì˜¤ë„ë¡ êµ¬ì„±, ì½”ë“œ í¸ì§‘ê¸° íƒ­ë„ í•„ìš”\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
