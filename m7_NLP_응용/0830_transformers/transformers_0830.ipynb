{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0830"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face의 'transformers' 기반 번역 챗봇(ko to en)\n",
    "- 모델은 OPUS-MT 프로젝트의 일부로 한영 번역 작업을 위해 사전 학습된 'Helsinki-NLP/opus-mt-ko-en' 사용\n",
    "- AutoTokenizer: 이 클래스는 모델에 대한 텍스트 입력 전처리를 담당합니다. 텍스트를 토큰으로 분할하고, 모델에 필요한 특수 토큰을 추가하고, 토큰을 모델 어휘의 해당 ID로 변환하는 등 텍스트를 모델이 이해할 수 있는 형식으로 변환(토큰화)\n",
    "- AutoModelForSeq2SeqLM: 이 클래스는 번역을 포함하는 시퀀스 간 언어 모델링에 적합한 모델 아키텍처를 로드합니다. 이 모델은 번역과 같은 작업에서 변환기가 작동하는 방식을 이해하는 데 기본이 되는 인코더-디코더 구조를 사용\n",
    "-  KoreanToEnglishTranslator 인스턴스가 생성되면 지정된 model_name을 사용하여 토크나이저와 모델을 초기화\n",
    "- 토큰화: 한국어 텍스트를 모델이 처리할 수 있는 형식으로 토큰화합니다. return_tensors=\"pt\"는 출력이 PyTorch 텐서임을 나타내며 padding=True는 모든 시퀀스가 ​​동일한 길이로 채워지도록 보장\n",
    "- 모델 생성: 'generate' 메소드가 모델 객체에서 호출됩니다. 이 방법은 인코더가 먼저 입력 시퀀스(한국어 텍스트)를 일련의 표현으로 인코딩하는 전체 시퀀스 간 생성 프로세스를 캡슐화합니다. 그런 다음 디코더는 이러한 표현을 사용하여 한 번에 하나의 토큰씩 출력 시퀀스(영어 번역)를 생성\n",
    "- 디코딩: decode 메서드는 생성된 토큰 ID를 다시 읽을 수 있는 텍스트로 변환하고 처리에 사용된 특수 토큰을 생략\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/Helsinki-NLP/opus-mt-ko-en\n",
    "\n",
    "https://github.com/Helsinki-NLP/Tatoeba-Challenge/blob/master/models/kor-eng/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m translated_text\n\u001b[0;32m     14\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHelsinki-NLP/opus-mt-ko-en\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 15\u001b[0m translator \u001b[38;5;241m=\u001b[39m \u001b[43mKoreanToEnglishTranslator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m korean_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m안녕하세요, 저는 한국어를 배우고 있는 학생입니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     18\u001b[0m english_translation \u001b[38;5;241m=\u001b[39m translator\u001b[38;5;241m.\u001b[39mtranslate(korean_text)\n",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m, in \u001b[0;36mKoreanToEnglishTranslator.__init__\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m AutoModelForSeq2SeqLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n",
      "File \u001b[1;32md:\\pythonProject\\NLP\\venv\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:921\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class_py\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    920\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 921\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    922\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    923\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min order to use this tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    924\u001b[0m             )\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to build an AutoTokenizer.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mTOKENIZER_MAPPING\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    929\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "class KoreanToEnglishTranslator:\n",
    "    def __init__(self, model_name: str):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    def translate(self, text: str) -> str:\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True) # pt: PyTorch\n",
    "        outputs = self.model.generate(**inputs)\n",
    "        translated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return translated_text\n",
    "    \n",
    "model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n",
    "translator = KoreanToEnglishTranslator(model_name)\n",
    "\n",
    "korean_text = \"안녕하세요, 저는 한국어를 배우고 있는 학생입니다.\"\n",
    "english_translation = translator.translate(korean_text)\n",
    "print(f'korean_text: {korean_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean text: 안녕하세요, 저는 한국어를 배우고 있는 학생입니다.\n",
      "English translation: Hi, I'm a student learning Korean.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "\n",
    "class KoreanToEnglishTranslator:\n",
    "    def __init__(self, model_name: str):\n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing model: {e}\")\n",
    "            print(\n",
    "                \"Please make sure you have 'sentencepiece' and other required libraries installed.\"\n",
    "            )\n",
    "            raise\n",
    "\n",
    "    def translate(self, text: str) -> str:\n",
    "        try:\n",
    "            inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "            outputs = self.model.generate(**inputs)\n",
    "            translated_text = self.tokenizer.decode(\n",
    "                outputs[0], skip_special_tokens=True\n",
    "            )\n",
    "            return translated_text\n",
    "        except Exception as e:\n",
    "            print(f\"Error during translation: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "\n",
    "try:\n",
    "    model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n",
    "    translator = KoreanToEnglishTranslator(model_name)\n",
    "\n",
    "    korean_text = \"안녕하세요, 저는 한국어를 배우고 있는 학생입니다.\"\n",
    "    english_translation = translator.translate(korean_text)\n",
    "    print(f\"Korean text: {korean_text}\")\n",
    "    print(f\"English translation: {english_translation}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "korean_text: 안녕하세요, 저는 한국어를 배우고 있는 학생입니다.\n",
      "English translation: Hi, I'm a student learning Korean.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "class KoreanToEnglishTranslator:\n",
    "    def __init__(self, model_name: str):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    def translate(self, text: str) -> str:\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True)  # pt: PyTorch\n",
    "        outputs = self.model.generate(**inputs)\n",
    "        translated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return translated_text\n",
    "\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n",
    "translator = KoreanToEnglishTranslator(model_name)\n",
    "\n",
    "korean_text = \"안녕하세요, 저는 한국어를 배우고 있는 학생입니다.\"\n",
    "english_translation = translator.translate(korean_text)\n",
    "print(f\"korean_text: {korean_text}\")\n",
    "print(f\"English translation: {english_translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
