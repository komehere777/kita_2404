## 서설

- 데이터수집: 데이터분석에서 중요, 현장에서 필요한건 데이터, 데이터가 수집, 정제가 중요, 데이터를 만드는 과정이 없음, 회사에서는 그런 일을 하지만 가야지 배울수 있음, 회사는 이미 할수있는 사람을 원함
- 앞으로 2주간하는 일이 그런 일
- 어떻게 데이터를 확보해야 하는가
- 앞으로 데이터 거래가 활발해질것
- api, 크롤링 이런 부분이 실제 일의 80%

## 통계
- 고유값과 분산의 관계

각 고유벡터에 대응하는 고유값은 해당 축을 따라 데이터가 얼마나 분산(공분산)되어 있는지를 나타냅니다.
고유값이 클수록 해당 축을 따라 데이터의 분산이 크다는 것을 의미합니다. 즉, 데이터가 그 축 방향으로 많이 퍼져 있다는 뜻입니다.
PCA에서 고유값이 큰 축(주성분)을 선택하는 이유는 이 축이 데이터의 분산을 최대한 많이 설명하기 때문입니다. 이렇게 하면 차원을 축소하더라도 데이터의 중요한 정보(분산)가 최대한 유지됩니다.

- 주성분 분석에서 고유값이 큰 주성분을 선택하는 이유

이 주성분이 데이터의 분산을 많이 설명하므로 데이터의 주요 변동을 잘 포착할 수 있기 때문입니다. 따라서, 차원을 축소할 때도 데이터의 중요한 정보를 최대한 유지할 수 있습니다.

주성분분석은 차원 줄이는것이 목적, 각 변수간 공분산을 봄, 같이 퍼져있는 걸보는게 공분산, 단위에 따라 절대적인 기준이 달라, 그래서 그걸 -101로 구분한게 상관계수, 공분산은 그게 안됨, 주성분에서 말하는 분산은 공분산, 공분산이 크다면 같은 방향으로 간다는 의미, 고유벡터도 같은 방향, 분산의 크기가 고유값, 고유값이 큰걸 주성분으로 채택하면 됨

- 데이터 분포
확률분포는 이론적이며, 특정 사건이나 변수의 가능한 값과 그 값이 발생할 확률을 수학적으로 나타냅니다.
데이터 분포는 실제 관찰된 데이터의 값을 시각화하거나 요약하는 것이며, 실제 데이터셋의 특성을 분석하는 데 사용됩니다.
확률분포와 데이터 분포는 밀접하게 관련되어 있지만, 하나는 이론적이고 다른 하나는 실제 데이터를 다룬다는 점에서 차이가 있습니다.이론적 배경 제공

- 변수의 분포 왜곡도가 심하면 모델 성능에 악영향을 미칠 수 있는 이유

비대칭성 문제: 왜곡된 분포는 데이터의 비대칭성을 증가시키며, 이는 모델이 데이터의 실제 패턴을 파악하기 어렵게 만듭니다.
극단값 문제: 왜곡된 분포는 극단값(outliers)의 영향을 크게 받을 수 있어, 모델이 극단값에 과도하게 민감해질 수 있습니다.
특성 중요도 왜곡: 왜곡된 분포는 모델이 특정 변수의 중요도를 잘못 판단하게 할 수 있습니다.
피쳐 엔지니어링의 문제
우리가 배운건 표준화(실제 사용시 성과가 좋지는 않음)- 로그변화도 사용, 최근에는 파워트랜스포머 사용` , 정규화

- [PowerTransformer의 정규화 방식] 
PowerTransformer는 데이터를 정규 분포에 가깝게 만들기 위해 두 가지 주요 변환 방법을 제공합니다. 두 방법 모두 데이터를 특정 함수에 따라 변환하여 데이터의 분포를 정규 분포에 가깝게 만듭니다.

- 모델 왜곡의 부작용
PowerTransformer를 사용한 변환은 일반적으로 데이터의 정규성을 높여 머신러닝 모델의 성능을 향상시키는 데 유용. 그러나 몇 가지 잠재적인 부작용이 있을 수 있습니다:

데이터가 변환되면 원래 데이터의 스케일과 해석이 달라질 수 있습니다. 예를 들어, 소득 데이터를 로그 변환하면 원래 단위의 의미가 사라지게 됩니다.
데이터의 변환은 모델의 복잡성을 증가시킬 수 있으며, 특히 작은 데이터셋에서는 모델이 과적합(overfitting)될 위험이 있습니다- 과적합을 피하기 위해 변환하는데... 이는 변환이 데이터의 노이즈를 과도하게 반영하는 경우에 발생할 수 있습니다.
일부 데이터는 특정 변환에 적합하지 않을 수 있습니다. 예를 들어, Box-Cox 변환은 음수 값을 처리할 수 없으며, Yeo-Johnson 변환은 데이터가 매우 비정규적인 경우에는 항상 잘 동작하지 않을 수 있습니다.
변환 과정에서 데이터의 일부 정보가 손실될 수 있습니다. 이는 변환 함수가 데이터의 특정 특성을 평활화(1차원화)하거나 제거할 때 발생할 수 있습니다.

# 정규분포

- 특징
연속 확률분포 중 하나로, 데이터가 평균을 중심으로 좌우 대칭적인 형태를 띱니다. 평균, 중앙값, 최빈값이 모두 동일합니다.
선은 종 모양으로, 대부분의 데이터가 평균 근처에 몰려 있고, 평균에서 멀어질수록 데이터의 빈도가 급격히 감소합니다.
68-95-99.7 법칙
평균으로부터 1표준편차 이내에 데이터의 약 68%가 존재합니다.
평균으로부터 2표준편차 이내에 데이터의 약 95%가 존재합니다.
평균으로부터 3표준편차 이내에 데이터의 약 99.7%가 존재합니다.
중심극한정리에 의해 많은 자연 현상과 실험 결과가 정규분포를 따릅니다. 예를 들어, 사람들의 키, 시험 성적, 생산 공정의 오차 등이 정규 분포를 따르는 경우가 많습니다.

-데이터 분석에서 정규 분포의 활용 포인트

많은 통계 분석 방법은 데이터가 정규 분포를 따른다는 가정을 기반으로 합니다. 예를 들어, t-검정, ANOVA, 선형 회귀 분석(머신러닝에서는 정규분포보다 평가방법이 높은 것을 사용하니 정규분포가 아니여도 가능) 등은 데이터가 정규 분포를 따른다고 가정합니다.

정규 분포에서는 평균으로부터 멀리 떨어진 데이터 포인트는 이상치로 간주될 수 있습니다. 이는 이상치를 탐지하고 제거하는 데 유용합니다.

데이터가 정규 분포를 따르지 않는 경우, 정규 분포에 가깝게 변환함으로써 분석의 정확성을 높일 수 있습니다. PowerTransformer, 로그 변환 등이 사용됩니다. 정규분포여야 특징을 잘 찾아낼수있음, 왜곡이 발생하더라도 특징은 유지되면서 변환된다고 가정, 왜곡되는 부분은 감안하고 활용

정규 분포를 이용하여 신뢰 구간을 설정하고, 가설 검정(귀무가설, 대립가설등을 사용, 통계량 산정, p밸류산정, 공분산 산정, 이건 기계학습에 사용되지는 않음, 범주형 데이터를 따지는 경우에만 사용, 중요도 낮음, 개략적인것만 인식)을 수행할 수 있습니다(통계에서 사용). 이는 데이터의 불확실성을 평가하고, 통계적 유의성을 판단하는 데 도움을 줍니다.

정규 분포를 이용하면 특정 값이 발생할 확률을 계산할 수 있습니다. 이는 위험 평가, 품질 관리, 예측 모델링 등에서 유용합니다.

수학처럼 로지컬하게 답이 나오는게 아니라서 데이터분석이 어려움, 인사이트 뽑아내는 걸 기준삼아 답을 찾아야 함, 작은 실마리라도 활용하기 위해 변환 등이 필요함
