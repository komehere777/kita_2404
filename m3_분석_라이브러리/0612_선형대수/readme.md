# 선형대수 0612

## 서설

- 선형대수가 어떻게 데이터 분석에 적용되는지 잘 나와있지 않음
- 활용에 대한 부분이 부족한게 현실
- 이해의 폭을 넓혀서 응용할수있게 도움이 될수있게
- 오늘은 실제 적용부분, 어려울수있다.
- 어떻게 적용되나, 머신러닝 회귀모델, 차원축소(비지도 학습), 주성분분석, 신경망(딥러닝)-네트웍의 활용(행렬곱이 어떻게 적용되는지)
- 이렇게 적용, 활용되는지 경험
- 끝나고 통계, 수강생들이 가장 어려운 부분이라 함
- 그 통계도 학교 수업을 위한 통계, 데이터분석을 위한 통계는 잘 없음
- 데이터탐색을 위한 통계(문제나 사례중심으로 전개)
- 어떻게 문제를 해결할 것인가
- 기술통계(디스크립션, 설명), 추측통계(확률을 기반, 가설과 검증)
- 쓸데없는 내용은 다 빼고 진행
- 가중치- 행렬곱- 패턴을 더 잘알기 위해
- 컬럼은 그 컬럼마다 중요성이 다름
- 타이타닉 - 성별, 요금 등이 중요했음
- 예측했던 가중치가 오차가 적으면 성공
- 역전파로 가중치 개선(기울기가 나와서 미분해야함)
- 수정된 가중치로 계속 행렬곱
- 나중에는 비선형 활성화 함수도 적용
- 회귀모델은 비선형 모델로 수행
- 신경망은 선형변환 + 비선형변환

- 금요일 시험(20문제): 판다스, 넘파이, 과제로 낸거 위주로 나옴
- 다음주 크롤링(실습 점수로 채택)

## task0611 풀이중 체크사항

- 모델 파라미터와 가중치 행렬이 같은말
- 활성화 함수(ReLU, 시그모이드) 비선형
- 편향 벡터는 그냥 더하기
- y = np.dot(W,X) # 이게 맞는 표현, 가중치 먼저 그다음 입력 벡터, 표기만 이렇게 해준다고 생각해야 함
- 일반적인 선형변화에 활성화 함수 적용해주면 비선형 변환완료
- 시그모이드 함수는 분류 모델로 사용, 0.5기준으로 판단, 성공은 1, 실패는0 
- 렐루함수는 비선형, 음수값을 받으면 0
  
## 수업

### 고유값 및 고유벡터

- Av=λv를만족하는λ가고유값,v가고유벡터
- 이 방정식의 의미는 행렬 A가 고유벡터 v를 변환할 때, 고유벡터 v의 방향은 변하지 않고 크기만 λ 배로 변한다는 것이며 고유벡터는 행렬 변환에 의해 방향이 바뀌지 않는 특별한 벡터를 의미
- A행렬을 이용해 변환했지만 원래 벡터는 동일하고 크기만 바뀐것, 람다는 크기로 씀
- 차원축소에 사용, 고유값 크기로만 판단
- 행렬 A로 부터 고유값과 고유벡터를 구한다면...

### 행렬식

- 행렬식은 행렬이 나타내는 선형 변환의 스케일링(확장 또는 축소) 비율

### 선형대수가 사용되는 곳

- 회귀분석 : 가중치 구할때 사용
- 주성분 분석 : 고유값, 고유벡터사용하여 주성분 찾음
- 뉴럴 네트워크 : 가중치와 입력벡터의 행렬곱으로 출력 계산
- 클러스터링 : 데이터 포인트와 클러스터 중심간 거리 계산

### 회귀분석

```python
from numpy.linalg import inv
X_b = np.c_[np.ones((4,1)),X] #X에 절편 추가, 임의로 넣어 줌
beta = inv(X_b.T @ X_b)@X_b.T @ y
```

### PCA분석

```python
#데이터의 차원을 축소하기 위해 주성분 분석을 수행
from sklearn.decomposition import PCA
pca = PCA(n_components=2) #특성은 2개 설정
X_pca = pca.fit_transform(X)
print(X_pca,'\n')
print(pca.explained_variance_,'\n')
print(pca.components_)
```

### 군집분석

```python
from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=2, n_init='auto')
kmeans.fit(X)
print(kmeans.cluster_centers_)
print(kmeans.labels_)
```

