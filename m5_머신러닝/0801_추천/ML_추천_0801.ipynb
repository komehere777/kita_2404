{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0801"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추천 알고리즘\n",
    "크게 세 가지 주요 범주로 나눌 수 있습니다: 콘텐츠 기반 필터링(Content-Based Filtering), 협업 필터링(Collaborative Filtering), 그리고 하이브리드 필터링(Hybrid Filtering)입니다.\n",
    "\n",
    "콘텐츠 기반 필터링 (Content-Based Filtering)<br>\n",
    "콘텐츠 기반 필터링은 아이템의 특성(속성)을 기반으로 사용자가 선호할 만한 아이템을 추천하는 방법입니다.\n",
    "- 특징:\n",
    "  - 각 아이템의 속성을 벡터로 표현합니다.\n",
    "  - 사용자의 이전 행동(예: 사용자가 좋아한 아이템)으로부터 프로필을 생성합니다.\n",
    "  - 사용자가 좋아하는 아이템과 유사한 아이템을 추천합니다.\n",
    "- 예시:\n",
    "  - 영화 추천에서, 사용자가 좋아하는 영화의 장르, 감독, 배우 등의 특성을 기반으로 유사한 영화를 추천.\n",
    "  - 문서 추천에서, 사용자가 읽은 문서의 키워드, 주제 등을 분석하여 유사한 문서를 추천.\n",
    "- 장점:\n",
    "  - 새로운 아이템도 쉽게 추천할 수 있습니다(콜드 스타트 문제 해결 가능).- 사용자 초기 정보가 없어도 추천이 가능\n",
    "  - 사용자의 개별 취향을 잘 반영합니다.\n",
    "- 단점:\n",
    "  - 아이템의 모든 속성을 정의하고 분석하는 것이 어려울 수 있습니다.\n",
    "  - 사용자가 관심을 보이지 않은 속성은 추천하기 어렵습니다.\n",
    "\n",
    "협업 필터링 (Collaborative Filtering)<br>\n",
    "협업 필터링은 사용자와 아이템 간의 상호작용 데이터를 바탕으로 추천을 수행하는 방법입니다. 주로 사용자 간의 유사성 또는 아이템 간의 유사성을 이용합니다.\n",
    "- 사용자 기반 협업 필터링 (User-Based Collaborative Filtering):\n",
    "  - 사용자가 유사한 다른 사용자가 좋아한 아이템을 추천합니다.\n",
    "  - 예: 사용자 A와 B가 유사하다면, B가 좋아한 아이템을 A에게 추천.\n",
    "- 아이템 기반 협업 필터링 (Item-Based Collaborative Filtering):\n",
    "  - 사용자가 이전에 좋아한 아이템과 유사한 아이템을 추천합니다.\n",
    "  - 예: 영화 X와 Y가 유사하다면, X를 본 사용자는 Y도 좋아할 가능성이 높음.\n",
    "- 잠재요인 협업 필터링 (Latent Factor Collaborative Filtering): - 가장 많이 사용, 과제도 이것으로 진행\n",
    "  - 행렬 분해(Matrix Factorization) 기법을 사용하여 사용자와 아이템의 잠재요인을 학습합니다. - 사용자, 아이템으로 분해 후 잠재요인을 추출하여 추천\n",
    "  - 예: SVD (Singular Value Decomposition), NMF (Non-negative Matrix Factorization).\n",
    "- 장점:\n",
    "  - 아이템의 속성 정보 없이도 추천이 가능합니다.\n",
    "  - 다양한 사용자 행동 데이터를 활용하여 추천 성능이 좋습니다.\n",
    "- 단점:\n",
    "  - 새로운 사용자나 아이템에 대한 정보가 부족한 경우(콜드 스타트 문제) 추천이 어려움.\n",
    "  - 사용자나 아이템의 수가 많아질수록 계산량이 증가.\n",
    "\n",
    "하이브리드 필터링 (Hybrid Filtering)<br>\n",
    "하이브리드 필터링은 콘텐츠 기반 필터링과 협업 필터링을 결합하여 각 접근 방식의 단점을 보완하고 장점을 극대화하는 방법입니다.\n",
    "- 방법:\n",
    "  - 두 가지 방법의 결과를 결합하여 최종 추천을 생성합니다.\n",
    "  - 콘텐츠 기반 추천을 초기 단계에서 사용하고, 데이터가 쌓이고 난 이후 협업 필터링을 적용하는 방법.\n",
    "  - 모델을 결합하여(7:3) 새로운 하이브리드 모델을 학습하는 방법.\n",
    "- 장점:\n",
    "  - 각 방법의 장점을 결합하여 더 정확한 추천을 제공.\n",
    "  - 콜드 스타트 문제를 완화.\n",
    "  - 다양한 데이터 소스를 활용하여 추천의 다양성과 정확성 증가.\n",
    "- 단점:\n",
    "  - 구현이 복잡하고 계산 비용이 증가할 수 있음.\n",
    "  - 두 가지 방법의 적절한 조합을 찾기 어려울 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise 패키지\n",
    "- 파이썬으로 작성된 추천 시스템 라이브러리로, 다양한 추천 알고리즘을 쉽게 사용할 수 있게 도와줍니다.\n",
    "- Surprise는 특히 행렬 분해(Matrix Factorization)와 같은 협업 필터링 알고리즘을 구현하는 데 강력한 기능을 제공합니다.\n",
    "- 이 패키지는 사용자-아이템 상호작용 데이터를 기반으로 추천 모델을 구축하고 평가하는 과정을 매우 단순화합니다.\n",
    "\n",
    "- Surprise 패키지의 주요 기능\n",
    "  - 다양한 알고리즘 지원: Surprise는 다양한 추천 알고리즘을 제공합니다. 대표적인 알고리즘으로는 다음이 있습니다.\n",
    "    - 기본 알고리즘: NormalPredictor\n",
    "    - 협업 필터링: KNNBasic, KNNWithMeans, KNNBaseline\n",
    "    - 행렬 분해: SVD, SVD++, NMF\n",
    "    - 베이스라인 알고리즘: BaselineOnly\n",
    "  - 사용자 정의 데이터셋 지원: Surprise는 내장된 데이터셋 외에도 사용자 정의 데이터셋을 로드할 수 있는 기능을 제공합니다. CSV 파일이나 데이터프레임을 로드하여 사용할 수 있습니다.\n",
    "  - 모델 평가: Surprise는 다양한 평가 지표를 제공합니다. RMSE, MAE와 같은 지표를 사용하여 모델 성능을 평가할 수 있습니다. 또한, 교차 검증(Cross-validation)과 같은 평가 방법도 지원합니다.\n",
    "  - 쉽고 직관적인 API: Surprise는 간단하고 직관적인 API를 제공하여 추천 시스템을 쉽게 구현할 수 있도록 도와줍니다.\n",
    "\n",
    "- Surprise 패키지의 주요 모듈\n",
    "  - Dataset 모듈:\n",
    "    - Dataset.load_builtin(name): 내장된 데이터셋을 로드합니다.\n",
    "    - Dataset.load_from_file(file_path, reader): 파일로부터 데이터셋을 로드합니다.\n",
    "    - Dataset.load_from_df(df, reader): 데이터프레임으로부터 데이터셋을 로드합니다.\n",
    "  - Reader 모듈:\n",
    "    - Reader(line_format, sep, rating_scale): 사용자 정의 데이터셋을 로드할 때 사용되는 클래스입니다.\n",
    "  - Trainset 클래스:\n",
    "    - build_full_trainset(): 전체 데이터셋을 학습 데이터로 사용합니다.\n",
    "    - build_testset(): 전체 데이터셋을 테스트 데이터로 사용합니다.\n",
    "  - Prediction 모듈:\n",
    "    - accuracy.rmse(predictions): RMSE를 계산합니다.\n",
    "    - accuracy.mae(predictions): MAE를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
      "Done! Dataset ml-100k has been saved to C:\\Users\\Administrator/.surprise_data/ml-100k\n",
      "  user_id item_id  rating  timestamp\n",
      "0     196     242     3.0  881250949\n",
      "1     186     302     3.0  891717742\n",
      "2      22     377     1.0  878887116\n",
      "3     244      51     2.0  880606923\n",
      "4     166     346     1.0  886397596\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset\n",
    "\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "\n",
    "\n",
    "raw_ratings = data.raw_ratings\n",
    "\n",
    "df = pd.DataFrame(raw_ratings, columns=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.5173\n",
      "NomalPredictor RMSE: 1.5173338206055367\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, NormalPredictor\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# MovieLens 100k 데이터셋 로드\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "trainset, tsetset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# NomalPredictor 모델\n",
    "algo = NormalPredictor()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "predictions = algo.test(tsetset)\n",
    "\n",
    "# 예측 및 평가\n",
    "predictions = algo.test(tsetset)\n",
    "print(\"NomalPredictor RMSE:\", accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NormalPredictor:\n",
    "- 사용자나 아이템의 특성을 고려하지 않고, 단순히 평점의 분포를 기반으로 임의의 예측을 수행합니다. 평점의 평균과 표준편차를 사용하여 임의의 예측 값을 생성합니다.\n",
    "- 실제 추천 시스템에서는 잘 사용되지 않지만, 비교 기준으로 사용할 수 있습니다.\n",
    "- 데이터 형태: 사용자 ID, 아이템 ID, 평점, 타임스탬프\n",
    "- 작동 방식: 주어진 데이터의 평균과 표준편차를 기반으로 무작위 예측을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.5162\n",
      "NormalPredictor RMSE: 1.516205530344726\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, NormalPredictor\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "algo = NormalPredictor()\n",
    "algo.fit(trainset)\n",
    "\n",
    "predictions = algo.test(testset)\n",
    "print(\"NormalPredictor RMSE:\", accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNBasic: \n",
    "- 사용자 기반 또는 아이템 기반의 최근접 이웃 협업 필터링을 수행합니다. 사용자가 유사한 사용자 또는 유사한 아이템을 찾고, 그들의 평점을 기반으로 추천합니다.\n",
    "- 데이터 형태: 사용자 ID, 아이템 ID, 평점, 타임스탬프\n",
    "- 작동 방식: 유사도를 계산하여 최근접 이웃을 찾고, 이웃의 평점을 기반으로 예측합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "KNNBasic RMSE: 0.9852458325502054\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, KNNBasic\n",
    "\n",
    "algo_knnbasic = KNNBasic()\n",
    "algo_knnbasic.fit(trainset)\n",
    "\n",
    "predictions = algo_knnbasic.test(testset)\n",
    "print(\"KNNBasic RMSE:\", accuracy.rmse(predictions, verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNWithMeans\n",
    "- KNNWithMeans는 KNNBasic과 유사하지만, 각 사용자의 평균 평점을 고려하여 평점을 예측합니다.\n",
    "- 데이터 형태: 사용자 ID, 아이템 ID, 평점, 타임스탬프\n",
    "- 작동 방식: 유사도를 계산하여 최근접 이웃을 찾고, 이웃의 평점과 평균 평점을 사용하여 예측합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "KNNWithMeans RMSE: 0.957686914030168\n"
     ]
    }
   ],
   "source": [
    "from surprise import KNNWithMeans\n",
    "\n",
    "algo_knnwithmeans = KNNWithMeans()\n",
    "algo_knnwithmeans.fit(trainset)\n",
    "\n",
    "predictions = algo_knnwithmeans.test(testset)\n",
    "print(\"KNNWithMeans RMSE:\", accuracy.rmse(predictions, verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD (Singular Value Decomposition):\n",
    "- SVD는 행렬 분해 기반의 협업 필터링 알고리즘입니다. 사용자-아이템 평점 행렬을 분해하여 잠재 요인을 추출하고 이를 기반으로 평점을 예측합니다.\n",
    "- 데이터 형태: 사용자 ID, 아이템 ID, 평점, 타임스탬프\n",
    "- 작동 방식: 행렬 분해를 통해 사용자와 아이템의 잠재 요인을 학습하고, 이를 사용하여 평점을 예측합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD RMSE: 0.9443975669411006\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "\n",
    "algo_svd = SVD()\n",
    "algo_svd.fit(trainset)\n",
    "\n",
    "predictions = algo_svd.test(testset)\n",
    "print(\"SVD RMSE:\", accuracy.rmse(predictions, verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF (Non-negative Matrix Factorization):\n",
    "- 비음수 행렬 분해를 사용하는 알고리즘으로, 사용자와 아이템의 잠재 요인을 추출합니다.\n",
    "- 데이터 형태: 사용자 ID, 아이템 ID, 평점, 타임스탬프\n",
    "- 작동 방식: 행렬 분해를 통해 비음수 잠재 요인을 학습하고, 이를 사용하여 평점을 예측합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF RMSE: 0.9666664454539295\n"
     ]
    }
   ],
   "source": [
    "from surprise import NMF\n",
    "\n",
    "algo_nmf = NMF()\n",
    "algo_nmf.fit(trainset)\n",
    "\n",
    "predictions = algo_nmf.test(testset)\n",
    "print(\"NMF RMSE:\", accuracy.rmse(predictions, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Movie ID: 1536, Estimated Rating: 5\n",
      "Movie ID: 1293, Estimated Rating: 5\n",
      "Movie ID: 814, Estimated Rating: 5\n",
      "Movie ID: 1642, Estimated Rating: 5\n",
      "Movie ID: 1500, Estimated Rating: 5\n",
      "Movie ID: 1491, Estimated Rating: 5\n",
      "Movie ID: 1599, Estimated Rating: 5\n",
      "Movie ID: 1189, Estimated Rating: 5\n",
      "Movie ID: 1064, Estimated Rating: 5\n",
      "Movie ID: 1358, Estimated Rating: 5\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise import Dataset, KNNBasic\n",
    "\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "algo = (\n",
    "    KNNBasic()\n",
    ")  # 디폴트는 user_based=True 유사한 사용자를 찾아 이들의 평점을 기반으로 예측\n",
    "# user_based=False 유사한 아이템을 찾아 사용자가 해당 아이템에 매긴 평점을 기반으로 예측\n",
    "algo.fit(trainset)\n",
    "# 모든 영화에 대해 예측\n",
    "user_id = \"196\"\n",
    "items = trainset.all_items()\n",
    "\n",
    "predictions = []\n",
    "inner_id_list = [iid for iid in items]\n",
    "raw_id_list = [trainset.to_raw_iid(inner_id) for inner_id in inner_id_list]\n",
    "\n",
    "predictions = [algo.predict(user_id, raw_id) for raw_id in raw_id_list]\n",
    "\n",
    "predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "top_n = 10\n",
    "\n",
    "for pred in predictions[:top_n]:\n",
    "    print(f\"Movie ID: {pred.iid}, Estimated Rating: {pred.est}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie ID: 408, Estimated Rating: 4.6128793932226335\n",
      "Movie ID: 64, Estimated Rating: 4.600426630044257\n",
      "Movie ID: 50, Estimated Rating: 4.58643347961558\n",
      "Movie ID: 272, Estimated Rating: 4.559955270135188\n",
      "Movie ID: 483, Estimated Rating: 4.509077493089307\n",
      "Movie ID: 114, Estimated Rating: 4.480127469711624\n",
      "Movie ID: 302, Estimated Rating: 4.450423837338911\n",
      "Movie ID: 603, Estimated Rating: 4.446634159164688\n",
      "Movie ID: 178, Estimated Rating: 4.436707066362782\n",
      "Movie ID: 169, Estimated Rating: 4.410414598561401\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise import Dataset, KNNBasic, SVD\n",
    "\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "algo = (\n",
    "    SVD()\n",
    ")  # 디폴트는 user_based=True 유사한 사용자를 찾아 이들의 평점을 기반으로 예측\n",
    "# user_based=False 유사한 아이템을 찾아 사용자가 해당 아이템에 매긴 평점을 기반으로 예측\n",
    "algo.fit(trainset)\n",
    "# 모든 영화에 대해 예측\n",
    "user_id = \"196\"\n",
    "items = trainset.all_items()\n",
    "\n",
    "predictions = []\n",
    "inner_id_list = [iid for iid in items]\n",
    "raw_id_list = [trainset.to_raw_iid(inner_id) for inner_id in inner_id_list]\n",
    "\n",
    "predictions = [algo.predict(user_id, raw_id) for raw_id in raw_id_list]\n",
    "\n",
    "predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "top_n = 10\n",
    "\n",
    "for pred in predictions[:top_n]:\n",
    "    print(f\"Movie ID: {pred.iid}, Estimated Rating: {pred.est}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 1645)\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644]\n",
      "['657', '1249', '436', '12', '121', '3', '692', '233', '549', '409', '707', '186', '323', '125', '1290', '1428', '77', '951', '168', '812', '702', '520', '258', '249', '188', '872', '98', '1469', '507', '434', '128', '56', '150', '192', '265', '228', '528', '761', '137', '513', '411', '825', '50', '792', '319', '17', '8', '28', '172', '187', '161', '216', '209', '248', '153', '487', '194', '809', '414', '90', '135', '151', '712', '402', '58', '750', '182', '294', '576', '628', '237', '200', '204', '387', '269', '633', '871', '1017', '1149', '212', '164', '20', '195', '191', '790', '1147', '401', '91', '222', '495', '117', '567', '504', '699', '480', '271', '614', '1211', '510', '428', '300', '625', '42', '1032', '24', '288', '649', '131', '449', '321', '1', '23', '80', '111', '280', '515', '307', '527', '118', '944', '478', '720', '615', '423', '354', '632', '181', '231', '670', '333', '89', '99', '630', '241', '832', '100', '690', '183', '289', '654', '971', '7', '435', '257', '637', '685', '254', '642', '678', '208', '283', '535', '337', '14', '680', '1221', '718', '273', '326', '30', '380', '840', '473', '591', '51', '578', '403', '554', '463', '13', '813', '603', '655', '53', '650', '22', '162', '173', '86', '471', '675', '763', '969', '220', '801', '952', '291', '462', '968', '223', '70', '990', '101', '144', '9', '207', '88', '305', '762', '627', '124', '185', '1047', '293', '651', '324', '219', '226', '39', '734', '715', '584', '926', '322', '304', '133', '1126', '49', '756', '583', '281', '588', '95', '47', '445', '547', '251', '197', '285', '127', '236', '597', '705', '132', '474', '87', '393', '1022', '1039', '1347', '693', '179', '356', '97', '302', '537', '154', '688', '205', '357', '206', '1434', '313', '245', '476', '5', '190', '405', '1119', '735', '516', '736', '318', '420', '328', '724', '721', '552', '259', '511', '169', '571', '66', '1228', '455', '1157', '385', '4', '989', '1529', '1116', '410', '1471', '447', '230', '518', '928', '559', '175', '416', '659', '1263', '96', '864', '155', '573', '382', '260', '417', '157', '286', '508', '489', '618', '739', '886', '54', '274', '582', '94', '303', '497', '109', '71', '681', '682', '713', '941', '92', '469', '11', '134', '427', '198', '217', '466', '243', '418', '244', '81', '340', '234', '815', '604', '276', '684', '272', '166', '959', '292', '1110', '620', '312', '290', '180', '894', '55', '242', '352', '938', '264', '1011', '922', '609', '475', '689', '225', '83', '661', '874', '282', '1153', '25', '521', '74', '816', '479', '1166', '123', '748', '843', '143', '1090', '468', '1316', '1151', '347', '167', '1215', '740', '919', '211', '252', '218', '652', '48', '311', '896', '202', '138', '105', '1048', '810', '140', '494', '742', '176', '451', '496', '541', '1608', '215', '1091', '422', '31', '514', '316', '69', '714', '710', '596', '327', '539', '299', '717', '159', '79', '158', '174', '201', '1117', '465', '60', '38', '214', '32', '1337', '526', '332', '1478', '68', '339', '343', '505', '775', '977', '586', '1070', '275', '580', '325', '199', '1210', '923', '803', '129', '855', '1078', '331', '1118', '961', '145', '492', '668', '887', '210', '1064', '656', '568', '972', '429', '611', '365', '62', '238', '962', '102', '364', '636', '820', '298', '1005', '381', '673', '82', '486', '519', '349', '949', '1028', '747', '866', '250', '562', '306', '156', '189', '1556', '967', '484', '178', '457', '779', '1208', '550', '421', '367', '425', '1451', '933', '184', '1248', '419', '345', '621', '103', '239', '936', '1033', '1218', '287', '498', '570', '485', '358', '530', '856', '1135', '1012', '904', '988', '517', '443', '1031', '346', '399', '44', '826', '561', '778', '392', '1010', '266', '355', '483', '512', '441', '795', '767', '448', '888', '1511', '431', '350', '229', '797', '284', '270', '546', '73', '953', '1190', '955', '65', '623', '921', '986', '1059', '412', '501', '999', '6', '1168', '772', '160', '563', '901', '610', '648', '64', '170', '1041', '687', '432', '524', '879', '1006', '1298', '108', '15', '873', '177', '1045', '881', '529', '171', '10', '1007', '116', '315', '106', '544', '1049', '607', '1035', '731', '939', '433', '440', '139', '662', '261', '997', '755', '744', '52', '120', '818', '1046', '330', '221', '847', '2', '33', '430', '709', '639', '232', '759', '575', '616', '268', '860', '834', '1074', '851', '152', '308', '472', '844', '59', '509', '193', '1176', '973', '1137', '683', '295', '1092', '503', '783', '1547', '523', '889', '663', '27', '1019', '1029', '1098', '93', '1205', '1134', '665', '1037', '581', '1160', '602', '940', '147', '122', '833', '824', '631', '1220', '1079', '255', '749', '1338', '752', '1231', '196', '984', '697', '141', '406', '806', '1203', '841', '863', '781', '85', '645', '470', '1379', '240', '558', '21', '1013', '1016', '1421', '751', '1438', '336', '647', '1008', '374', '771', '1331', '566', '235', '386', '849', '1044', '1333', '371', '278', '213', '732', '569', '454', '606', '640', '1053', '845', '482', '467', '794', '1317', '378', '460', '404', '1234', '696', '383', '1187', '1051', '553', '916', '456', '1060', '902', '728', '679', '948', '458', '57', '1063', '1103', '1600', '1225', '338', '1278', '375', '310', '1245', '477', '979', '1071', '538', '931', '542', '672', '782', '1132', '1165', '956', '966', '1484', '1597', '1015', '297', '852', '279', '1193', '660', '1178', '785', '1093', '1062', '1174', '585', '1077', '1254', '446', '1315', '619', '765', '1036', '536', '1136', '829', '1014', '277', '351', '1003', '444', '1020', '1171', '768', '363', '929', '344', '256', '686', '730', '1139', '1521', '112', '1441', '565', '805', '408', '45', '1544', '577', '754', '388', '531', '992', '745', '506', '464', '46', '589', '407', '1076', '1120', '960', '1038', '776', '831', '1226', '1380', '658', '1142', '700', '373', '317', '61', '1464', '67', '703', '1244', '224', '1237', '1170', '525', '369', '897', '1238', '738', '26', '1034', '540', '704', '746', '1131', '885', '574', '400', '29', '900', '1121', '453', '993', '389', '737', '1652', '499', '1125', '579', '946', '985', '459', '924', '909', '107', '996', '126', '827', '493', '246', '370', '1555', '1185', '163', '379', '488', '1442', '1150', '203', '1101', '148', '1198', '1085', '110', '1488', '780', '646', '1042', '934', '877', '84', '1412', '63', '823', '1439', '800', '500', '1197', '320', '1004', '34', '882', '396', '1067', '1479', '898', '978', '1214', '136', '1089', '296', '40', '1164', '41', '664', '1023', '770', '227', '398', '716', '439', '1163', '970', '796', '1297', '43', '1213', '1552', '1000', '72', '1113', '995', '1303', '908', '943', '366', '1152', '557', '669', '1284', '1612', '1466', '391', '461', '958', '1025', '1052', '1537', '998', '1530', '1264', '836', '560', '764', '502', '142', '362', '870', '875', '1540', '895', '1267', '19', '1497', '634', '372', '802', '612', '963', '1009', '945', '880', '876', '676', '413', '149', '334', '601', '838', '1345', '1602', '671', '1446', '342', '1206', '1489', '723', '786', '1217', '613', '1061', '890', '437', '1311', '865', '394', '729', '1099', '753', '329', '18', '359', '301', '114', '1336', '1282', '635', '361', '1247', '975', '1286', '846', '1285', '743', '1662', '622', '130', '1240', '821', '490', '1133', '1129', '641', '572', '769', '608', '592', '893', '1065', '532', '1276', '424', '522', '1359', '1405', '1183', '774', '1235', '954', '950', '1127', '1066', '1018', '1628', '1384', '1199', '878', '965', '861', '837', '1426', '1073', '1114', '1106', '1272', '368', '1167', '1385', '16', '481', '911', '760', '548', '867', '1542', '1413', '1095', '991', '819', '1105', '1326', '708', '892', '1483', '1040', '314', '1191', '1219', '725', '930', '1050', '741', '397', '727', '1416', '262', '1563', '426', '1265', '36', '1308', '360', '384', '935', '1058', '1576', '1437', '1514', '1250', '691', '1672', '629', '452', '1406', '35', '932', '789', '903', '1140', '1204', '450', '1480', '1088', '1229', '1364', '719', '1392', '353', '1224', '1535', '146', '263', '1109', '791', '1192', '395', '1440', '784', '438', '883', '1273', '644', '556', '1545', '694', '115', '1321', '1411', '981', '1097', '1196', '817', '1313', '1179', '1456', '733', '491', '1069', '1522', '1305', '1280', '905', '666', '869', '854', '674', '1084', '1083', '942', '1021', '1538', '376', '1592', '1335', '758', '917', '76', '653', '605', '1401', '1332', '1462', '1312', '1277', '862', '937', '1300', '1246', '1239', '1172', '253', '722', '1057', '1595', '1324', '594', '1086', '1291', '165', '638', '1515', '1314', '1495', '1283', '859', '906', '1376', '1527', '1124', '695', '1367', '1102', '533', '787', '1459', '1289', '804', '590', '1357', '914', '1001', '1508', '1232', '1188', '1094', '1268', '1082', '983', '1454', '1503', '1475', '1375', '390', '1296', '757', '1299', '899', '1623', '1378', '853', '1141', '1622', '982', '1108', '808', '1524', '415', '1424', '1368', '1407', '1397', '1423', '828', '884', '1056', '925', '1159', '1582', '1269', '1227', '1444', '1258', '564', '1502', '915', '1255', '974', '1382', '1275', '1184', '1274', '1261', '1112', '1194', '1115', '555', '910', '920', '617', '595', '1087', '1570', '1350', '726', '947', '980', '1100', '1585', '587', '1107', '37', '1175', '624', '1024', '842', '1400', '1257', '1055', '1342', '1144', '1448', '1154', '1182', '551', '918', '1393', '1043', '1615', '1353', '1629', '835', '1431', '1209', '1417', '1343', '1374', '1295', '543', '309', '442', '545', '1513', '1143', '1054', '1318', '1579', '1589', '1500', '1414', '994', '1068', '976', '1610', '1531', '1394', '1409', '711', '667', '335', '1145', '1096', '1281', '1223', '78', '1620', '1161', '907', '1243', '1435', '1123', '701', '598', '1670', '1507', '626', '1181', '247', '1639', '1432', '1279', '643', '1002', '799', '1567', '1216', '1351', '1155', '807', '773', '1377', '1354', '1355', '1146', '1200', '912', '1307', '341', '1509', '698', '1158', '1517', '1512', '1403', '1443', '1271', '1288', '1256', '1340', '1180', '1266', '1598', '1262', '1539', '1541', '267', '1156', '113', '1404', '811', '1030', '1195', '1138', '1344', '1565', '1445', '987', '1365', '1222', '1386', '777', '1189', '1080', '1328', '534', '1148', '1665', '1510', '1259', '1551', '1468', '1330', '104', '1473', '1609', '1075', '1410', '1398', '1111', '348', '1186', '1659', '1465', '1584', '964', '1241', '1381', '1419', '1560', '1395', '1202', '1603', '1501', '1356', '1128', '1642', '1636', '1207', '1518', '1467', '377', '1422', '1162', '798', '1252', '1532', '1492', '1242', '1415', '1173', '1516', '593', '1396', '1236', '706', '1373', '1499', '1425', '1436', '1230', '1558', '1389', '1449', '1534', '1383', '830', '1645', '1650', '1251', '1605', '1169', '1177', '1474', '766', '1287', '1387', '1260', '1371', '1591', '1594', '119', '1322', '1388', '1557', '927', '1450', '1233', '1360', '1606', '1496', '1081', '1302', '1306', '1346', '1301', '75', '1370', '1429', '793', '1319', '1494', '1072', '1631', '1026', '1586', '839', '1677', '1402', '1361', '1607', '1643', '1320', '1418', '1640', '1504', '1470', '1481', '1349', '1253', '1294', '891', '1528', '1578', '1568', '1476', '1673', '1520', '1627', '1458', '1430', '1656', '1506', '1601', '1569', '1553', '1399', '1369', '1408', '1678', '1646', '1616', '1427', '822', '1559', '848', '1619', '1104', '913', '1611', '1486', '857', '957', '1654', '1212', '1523', '1641', '1027', '1329', '1372', '1433', '600', '599', '1624', '1676', '1310', '788', '1644', '1341', '850', '1491', '1649', '1323', '1293', '1358', '868', '1635', '1339', '1519', '1566', '1477', '1681', '1663', '1130', '1604', '1490', '1391', '1621', '1460', '1533', '1472', '1587', '1348', '1455', '1667', '1122', '1664', '1325', '1574', '814', '1548', '1270', '1485', '1669', '1304', '1668', '1572', '1420', '1452', '1651', '1573', '1661', '1588', '1682', '1614', '1593', '1657', '1550', '1453', '1461', '1390', '1561', '1580', '1309', '1581', '1658', '1463', '1638', '1482', '1617', '1613', '1666', '1625', '1655', '1505', '1201', '1571', '858', '1583', '1618', '1334', '1633', '1575', '1599', '1327']\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from surprise import Dataset, KNNBasic, SVD\n",
    "\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "algo = (\n",
    "    SVD()\n",
    ")  # 디폴트는 user_based=True 유사한 사용자를 찾아 이들의 평점을 기반으로 예측\n",
    "# user_based=False 유사한 아이템을 찾아 사용자가 해당 아이템에 매긴 평점을 기반으로 예측\n",
    "algo.fit(trainset)\n",
    "# 모든 영화에 대해 예측\n",
    "user_id = \"196\"\n",
    "items = trainset.all_items()\n",
    "\n",
    "predictions = []\n",
    "inner_id_list = [iid for iid in items]\n",
    "raw_id_list = [trainset.to_raw_iid(inner_id) for inner_id in inner_id_list]\n",
    "\n",
    "print(items)\n",
    "print(inner_id_list)\n",
    "print(raw_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surprise.dataset.DatasetAutoFolds"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 크기: (100000, 4)\n",
      "\n",
      "데이터셋 정보:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   user       100000 non-null  object \n",
      " 1   item       100000 non-null  object \n",
      " 2   rating     100000 non-null  float64\n",
      " 3   timestamp  100000 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 3.1+ MB\n",
      "None\n",
      "\n",
      "데이터셋 처음 5개 행:\n",
      "  user item  rating  timestamp\n",
      "0  196  242     3.0  881250949\n",
      "1  186  302     3.0  891717742\n",
      "2   22  377     1.0  878887116\n",
      "3  244   51     2.0  880606923\n",
      "4  166  346     1.0  886397596\n",
      "\n",
      "기술 통계:\n",
      "              rating\n",
      "count  100000.000000\n",
      "mean        3.529860\n",
      "std         1.125674\n",
      "min         1.000000\n",
      "25%         3.000000\n",
      "50%         4.000000\n",
      "75%         4.000000\n",
      "max         5.000000\n",
      "\n",
      "유니크한 사용자 수: 943\n",
      "유니크한 아이템(영화) 수: 1682\n",
      "평점 범위: 1.0 에서 5.0\n",
      "\n",
      "평점 분포:\n",
      "rating\n",
      "1.0     6110\n",
      "2.0    11370\n",
      "3.0    27145\n",
      "4.0    34174\n",
      "5.0    21201\n",
      "Name: count, dtype: int64\n",
      "\n",
      "사용자별 평점 수 통계:\n",
      "count    943.000000\n",
      "mean     106.044539\n",
      "std      100.931743\n",
      "min       20.000000\n",
      "25%       33.000000\n",
      "50%       65.000000\n",
      "75%      148.000000\n",
      "max      737.000000\n",
      "Name: rating, dtype: float64\n",
      "\n",
      "아이템(영화)별 평점 수 통계:\n",
      "count    1682.000000\n",
      "mean       59.453032\n",
      "std        80.383846\n",
      "min         1.000000\n",
      "25%         6.000000\n",
      "50%        27.000000\n",
      "75%        80.000000\n",
      "max       583.000000\n",
      "Name: rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터셋 로드\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "\n",
    "# 전체 데이터셋을 pandas DataFrame으로 변환\n",
    "df = pd.DataFrame(data.raw_ratings, columns=[\"user\", \"item\", \"rating\", \"timestamp\"])\n",
    "\n",
    "# 데이터셋 기본 정보 출력\n",
    "print(\"데이터셋 크기:\", df.shape)\n",
    "print(\"\\n데이터셋 정보:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n데이터셋 처음 5개 행:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n기술 통계:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n유니크한 사용자 수:\", df[\"user\"].nunique())\n",
    "print(\"유니크한 아이템(영화) 수:\", df[\"item\"].nunique())\n",
    "print(\"평점 범위:\", df[\"rating\"].min(), \"에서\", df[\"rating\"].max())\n",
    "\n",
    "# 평점 분포\n",
    "print(\"\\n평점 분포:\")\n",
    "print(df[\"rating\"].value_counts().sort_index())\n",
    "\n",
    "# 사용자별 평점 수\n",
    "user_ratings = df.groupby(\"user\")[\"rating\"].count()\n",
    "print(\"\\n사용자별 평점 수 통계:\")\n",
    "print(user_ratings.describe())\n",
    "\n",
    "# 아이템(영화)별 평점 수\n",
    "item_ratings = df.groupby(\"item\")[\"rating\"].count()\n",
    "print(\"\\n아이템(영화)별 평점 수 통계:\")\n",
    "print(item_ratings.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3.0</td>\n",
       "      <td>880175444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5.0</td>\n",
       "      <td>879795543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>874795795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>882399156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3.0</td>\n",
       "      <td>879959583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1    2          3\n",
       "0      196   242  3.0  881250949\n",
       "1      186   302  3.0  891717742\n",
       "2       22   377  1.0  878887116\n",
       "3      244    51  2.0  880606923\n",
       "4      166   346  1.0  886397596\n",
       "...    ...   ...  ...        ...\n",
       "99995  880   476  3.0  880175444\n",
       "99996  716   204  5.0  879795543\n",
       "99997  276  1090  1.0  874795795\n",
       "99998   13   225  2.0  882399156\n",
       "99999   12   203  3.0  879959583\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터셋 로드\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "\n",
    "# 전체 데이터셋을 pandas DataFrame으로 변환\n",
    "df = pd.DataFrame(data.raw_ratings)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 아이디 9는 영화 아이디 42의 평점 없음\n",
      "    movieId                   title              genres\n",
      "38       42  Dead Presidents (1995)  Action|Crime|Drama\n",
      "user: 9          item: 42         r_ui = None   est = 3.13   {'was_impossible': False}\n",
      "[41, 187, 223, 371, 627, 922, 923, 1037, 1095, 1198, 1270, 1674, 1987, 2011, 2012, 2023, 2300, 2877, 2901, 3173, 3328, 3735, 4131, 4558, 4993, 5218, 5378, 5445, 5447, 5451, 5481, 5507, 5841, 5843, 5872, 5890, 5891, 5893, 5902, 5952, 5956, 5962, 5965, 5988, 6001, 6044]\n",
      "평점 매긴 영화수: 46 추천대상 영화수: 9696 전체 영화수: 9742\n",
      "평점 매긴 영화수: 46 추천대상 영화수: 9696 전체 영화수: 9742\n",
      "##### Top-10 추천 영화 리스트 #####\n",
      "Usual Suspects, The (1995) : 4.306302135700814\n",
      "Star Wars: Episode IV - A New Hope (1977) : 4.281663842987387\n",
      "Pulp Fiction (1994) : 4.278152632122759\n",
      "Silence of the Lambs, The (1991) : 4.226073566460876\n",
      "Godfather, The (1972) : 4.1918097904381995\n",
      "Streetcar Named Desire, A (1951) : 4.154746591122658\n",
      "Star Wars: Episode V - The Empire Strikes Back (1980) : 4.122016128534504\n",
      "Star Wars: Episode VI - Return of the Jedi (1983) : 4.108009609093436\n",
      "Goodfellas (1990) : 4.083464936588478\n",
      "Glory (1989) : 4.07887165526957\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "from surprise.dataset import DatasetAutoFolds\n",
    "\n",
    "\n",
    "# CSV 파일 경로 설정\n",
    "ratings_file_path = r\"D:\\kdt_240424\\workspace\\M5_ML\\data\\ratings.csv\"\n",
    "movies_file_path = r\"D:\\kdt_240424\\workspace\\M5_ML\\data\\movies.csv\"\n",
    "\n",
    "# ratings 데이터 로드\n",
    "ratings = pd.read_csv(ratings_file_path)\n",
    "\n",
    "# DatasetAutoFolds 클래스를 ratings.csv 파일 기반으로 생성\n",
    "reader = Reader(\n",
    "    line_format=\"user item rating timestamp\", sep=\",\", rating_scale=(0.5, 5.0)\n",
    ")\n",
    "data_folds = DatasetAutoFolds(\n",
    "    ratings_file=r\"D:\\kdt_240424\\workspace\\M5_ML\\data\\ratings_noh.csv\",\n",
    "    reader=reader,\n",
    ")\n",
    "\n",
    "# 전체 데이터를 학습 데이터로 생성\n",
    "trainset = data_folds.build_full_trainset()\n",
    "algo = SVD(n_epochs=20, n_factors=50, random_state=0)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# movies 데이터 로드\n",
    "movies = pd.read_csv(movies_file_path)\n",
    "\n",
    "# userId=9 의 movieId 데이터 추출하여 movieId=42 데이터가 있는지 확인\n",
    "movieIds = ratings[ratings[\"userId\"] == 9][\"movieId\"]\n",
    "\n",
    "if movieIds[movieIds == 42].count() == 0:\n",
    "    print(\"사용자 아이디 9는 영화 아이디 42의 평점 없음\")\n",
    "\n",
    "print(movies[movies[\"movieId\"] == 42])\n",
    "\n",
    "uid = str(9)\n",
    "iid = str(42)\n",
    "\n",
    "pred = algo.predict(uid, iid, verbose=True)\n",
    "print(ratings[ratings[\"userId\"] == 9][\"movieId\"].tolist())\n",
    "\n",
    "\n",
    "# 사용자가 보지 않은 영화 목록 생성 함수\n",
    "def get_unseen_surprise(ratings, movies, userId):\n",
    "    seen_movies = ratings[ratings[\"userId\"] == userId][\"movieId\"].tolist()\n",
    "    total_movies = movies[\"movieId\"].tolist()\n",
    "    unseen_movies = [movie for movie in total_movies if movie not in seen_movies]\n",
    "    print(\n",
    "        \"평점 매긴 영화수:\",\n",
    "        len(seen_movies),\n",
    "        \"추천대상 영화수:\",\n",
    "        len(unseen_movies),\n",
    "        \"전체 영화수:\",\n",
    "        len(total_movies),\n",
    "    )\n",
    "    return unseen_movies\n",
    "\n",
    "\n",
    "unseen_movies = get_unseen_surprise(ratings, movies, 9)\n",
    "\n",
    "\n",
    "# 영화 추천 함수\n",
    "def recomm_movie_by_surprise(algo, userId, unseen_movies, top_n=10):\n",
    "    predictions = [algo.predict(str(userId), str(movieId)) for movieId in unseen_movies]\n",
    "\n",
    "    def sortkey_est(pred):\n",
    "        return pred.est\n",
    "\n",
    "    predictions.sort(key=sortkey_est, reverse=True)\n",
    "    top_predictions = predictions[:top_n]\n",
    "\n",
    "    top_movie_ids = [int(pred.iid) for pred in top_predictions]\n",
    "    top_movie_rating = [pred.est for pred in top_predictions]\n",
    "    top_movie_titles = movies[movies.movieId.isin(top_movie_ids)][\"title\"]\n",
    "    top_movie_preds = [\n",
    "        (id, title, rating)\n",
    "        for id, title, rating in zip(top_movie_ids, top_movie_titles, top_movie_rating)\n",
    "    ]\n",
    "\n",
    "    return top_movie_preds\n",
    "\n",
    "\n",
    "unseen_movies = get_unseen_surprise(ratings, movies, 9)\n",
    "top_movie_preds = recomm_movie_by_surprise(algo, 9, unseen_movies, top_n=10)\n",
    "\n",
    "print(\"##### Top-10 추천 영화 리스트 #####\")\n",
    "for top_movie in top_movie_preds:\n",
    "    print(top_movie[1], \":\", top_movie[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
