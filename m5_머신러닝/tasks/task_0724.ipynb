{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "# FutureWarning 경고 메시지를 무시하도록 설정\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task1_0724. Wine 데이터셋에 대하여 SVM 모델에 3개의 커널을 적용하여 학습 및 평가 결과를 출력하세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "커널 linear일때 정확도 : 1.0000\n",
      "커널 poly일때 정확도 : 0.8333\n",
      "커널 rbf일때 정확도 : 0.8056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "wine = load_breast()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "kernels = ['linear','poly', 'rbf']\n",
    "\n",
    "accuracy_dict = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    svm = SVC(kernel=kernel, C=1, random_state=10)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_dict[kernel] = accuracy\n",
    "    print(f\"커널 {kernel}일때 정확도 : {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task2_0724. breast_cancer dataset으로 랜덤포레스트를 적용하여 모델링 및 평가를 아래의 하이퍼 파라미터를 이용하여 수행한 후 최적의 하이퍼파라미터를 구하세요.\n",
    "\n",
    "- 'n_estimators': [50, 100, 200],\n",
    "- 'max_depth': [None, 10, 20],\n",
    "- 'max_features': ['auto', 'sqrt', 'log2'],\n",
    "- 'min_samples_split': [2, 5, 10],\n",
    "- 'min_samples_leaf': [1, 2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n estmator 50 의 정확도 : 0.9649 \n",
      "n estmator 100 의 정확도 : 0.9649 \n",
      "n estmator 200 의 정확도 : 0.9649 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "wine = load_breast_cancer()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "n_estimators = [50, 100, 200]\n",
    "max_depth = [None, 10, 20]\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "for estimator in n_estimators:\n",
    "    clf = RandomForestClassifier(n_estimators=estimator, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print(f'n estmator {estimator} 의 정확도 : {accuracy_score(y_test, pred):.4f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth None 의 정확도 : 0.9649 \n",
      "max depth 10 의 정확도 : 0.9649 \n",
      "max depth 20 의 정확도 : 0.9649 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "wine = load_breast_cancer()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "n_estimators = [50, 100, 200]\n",
    "max_depth = [None, 10, 20]\n",
    "max_features = [\"auto\", \"sqrt\", \"log2\"]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "for depth in max_depth:\n",
    "    clf = RandomForestClassifier(max_depth=depth, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print(f\"max depth {depth} 의 정확도 : {accuracy_score(y_test, pred):.4f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max feature sqrt 의 정확도 : 0.9649 \n",
      "max feature log2 의 정확도 : 0.9649 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "wine = load_breast_cancer()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "n_estimators = [50, 100, 200]\n",
    "max_depth = [None, 10, 20]\n",
    "# max_features = [\"auto\", \"sqrt\", \"log2\"]\n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "for feature in max_features:\n",
    "    clf = RandomForestClassifier(max_features=feature, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print(f\"max feature {feature} 의 정확도 : {accuracy_score(y_test, pred):.4f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min samples split 2 의 정확도 : 0.9649 \n",
      "min samples split 5 의 정확도 : 0.9649 \n",
      "min samples split 10 의 정확도 : 0.9649 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "wine = load_breast_cancer()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "n_estimators = [50, 100, 200]\n",
    "max_depth = [None, 10, 20]\n",
    "# max_features = [\"auto\", \"sqrt\", \"log2\"]\n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "for split in min_samples_split:\n",
    "    clf = RandomForestClassifier(min_samples_split=split, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print(\n",
    "        f\"min samples split {split} 의 정확도 : {accuracy_score(y_test, pred):.4f} \"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_leaf 1 의 정확도 : 0.9649 \n",
      "min_samples_leaf 2 의 정확도 : 0.9649 \n",
      "min_samples_leaf 4 의 정확도 : 0.9649 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "wine = load_breast_cancer()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "n_estimators = [50, 100, 200]\n",
    "max_depth = [None, 10, 20]\n",
    "# max_features = [\"auto\", \"sqrt\", \"log2\"]\n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "for leaf in min_samples_leaf:\n",
    "    clf = RandomForestClassifier(min_samples_leaf=leaf, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print(f\"min_samples_leaf {leaf} 의 정확도 : {accuracy_score(y_test, pred):.4f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task3_0724. 데이터셋 개선, 오늘 배운 모델 적용, 탐색적분석을 통한 파생변수 적용하고 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 개선\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"adult_incomes.csv\")\n",
    "data.dropna(inplace=True)\n",
    "# 이상치 제거 data['capital-gain'] max값 제거\n",
    "data = data[data[\"capital-gain\"] < 99990]\n",
    "\n",
    "# 파생변수 작성\n",
    "data[\"capital_diff\"] = data[\"capital-gain\"] - data[\"capital-loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    30014.000000\n",
       "mean        38.399747\n",
       "std         13.134518\n",
       "min         17.000000\n",
       "25%         28.000000\n",
       "50%         37.000000\n",
       "75%         47.000000\n",
       "max         90.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추가 파생변수 작성 - 나이 카테고리화\n",
    "data.age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = data.age.values\n",
    "category = ['teenager','young adult','adult','elderly']\n",
    "data['age_cat'] = pd.cut(ages, bins=[17, 28, 37,47, 90], labels=category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수 인코딩\n",
    "categorical_features = [\n",
    "    \"workclass\",\n",
    "    \"education\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"native-country\",\n",
    "    \"income\",\n",
    "    \"age_cat\",\n",
    "]\n",
    "\n",
    "data = pd.get_dummies(data, columns=categorical_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 30014 entries, 0 to 32560\n",
      "Columns: 101 entries, age to age_cat_elderly\n",
      "dtypes: bool(94), int64(7)\n",
      "memory usage: 4.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 선택및 독립변수 , 종속변수 분리\n",
    "X = data.drop(\"income_>50K\", axis=1)\n",
    "y = data[\"income_>50K\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 표준화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.8094\n"
     ]
    }
   ],
   "source": [
    "# 분류 모델 적용\n",
    "# 결정 트리\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print(\"예측 정확도: {0:.4f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.8301\n"
     ]
    }
   ],
   "source": [
    "# knn\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test)\n",
    "print(\"예측 정확도: {0:.4f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "커널 linear일때 정확도 : 0.8494\n",
      "커널 poly일때 정확도 : 0.8411\n",
      "커널 rbf일때 정확도 : 0.8492\n"
     ]
    }
   ],
   "source": [
    "# svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "kernels = [\"linear\", \"poly\", \"rbf\"]\n",
    "\n",
    "accuracy_dict = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    svm = SVC(kernel=kernel, C=1, random_state=10)\n",
    "    svm.fit(X_train, y_train)\n",
    "    pred = svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    accuracy_dict[kernel] = accuracy\n",
    "    print(f\"커널 {kernel}일때 정확도 : {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting 분류기 정확도: 0.8407\n",
      "KNeighborsClassifier 정확도: 0.8301\n",
      "SVC 정확도: 0.8494\n"
     ]
    }
   ],
   "source": [
    "# 앙상블 기법\n",
    "# 정확도 높았던 knn과 svm의 linear커널 조합\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "svm = SVC(kernel='linear', C=1, random_state=10)\n",
    "\n",
    "vo_clf = VotingClassifier(estimators=[('KNN', knn),('SVC',svm)], voting='hard')\n",
    "\n",
    "vo_clf.fit(X_train, y_train)\n",
    "pred = vo_clf.predict(X_test)\n",
    "print(\"Voting 분류기 정확도: {0:.4f}\".format(accuracy_score(y_test, pred)))\n",
    "\n",
    "classifiers = [knn, svm]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    class_name = classifier.__class__.__name__\n",
    "    print(f\"{class_name} 정확도: {accuracy_score(y_test, pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤 포레스트 정확도: 0.8557\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 포레스트\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(f\"랜덤 포레스트 정확도: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
